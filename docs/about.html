

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>About Multi-Armed Bandits &mdash; MABWiser 1.9.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="author" title="About these documents" href="#" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Installation" href="installation.html" />
    <link rel="prev" title="MABWiser Contextual Multi-Armed Bandits" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> MABWiser
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">About Multi-Armed Bandits</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Usage Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="new_bandit.html">Adding a New Bandit</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">MABWiser Public API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MABWiser</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>About Multi-Armed Bandits</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/about.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="about-multi-armed-bandits">
<span id="about"></span><h1>About Multi-Armed Bandits<a class="headerlink" href="#about-multi-armed-bandits" title="Permalink to this headline">¶</a></h1>
<p>There are many real-world situations in which we have to decide between multiple options yet we are only able to learn the best course of action by testing each option sequentially.</p>
<p><strong>Multi-armed bandit (MAB)</strong> algorithms are suitable for such sequential, online decision making problems under uncertainty.
As such, they play an important part in many machine learning applications in internet advertising, recommendation engines, and clinical trials among many others.</p>
<div class="admonition-exploration-vs-exploitation admonition">
<p class="first admonition-title">Exploration vs. Exploitation</p>
<p class="last">In this setting, for each and every renewed decision we face an underlying question: Do we stick to what we know and receive an expected result (“<strong>exploit</strong>”) or choose an option we do not know much about and potentially learn something new (“<strong>explore</strong>”)?</p>
</div>
<p><strong>Problem Definition:</strong> In a multi-armed bandits problem, the model of outcomes is unknown, and the outcomes can be deterministic
or stochastic. The agent needs to make a sequence of decisions in time <em>1, 2, …, T</em>.
At each time <em>t</em> the agent is given a set of <em>K</em> arms, and it has to decide which arm to pull.
After pulling an arm, it receives a <em>reward</em> of that arm, and the rewards of other arms are unknown.
In a stochastic setting the reward of an arm is sampled from some unknown distribution. There exist situations where we also observe side information at each time <em>t</em>.
This side information is referred to as <em>context</em>. The arm that has the highest expected reward may be different given different contexts.
This variant is called <strong>contextual multi-armed bandits</strong>. Overall, the objective is to maximize the cumulative expected reward in the long run.</p>
<hr class="docutils" />
<p>For more information, we refer to these excellent resources:</p>
<ol class="arabic simple">
<li><a class="reference external" href="http://proceedings.mlr.press/v9/lu10a/lu10a.pdf">Contextual Multi-Armed Bandits</a>, Tyler Lu <em>et. al</em>. Proc. of Machine Learning Research, 2010</li>
<li><a class="reference external" href="https://arxiv.org/pdf/1508.03326.pdf">A Survey on Contextual Multi-armed Bandits</a>, Li Zhou, Carnegie Mellon University, arXiv, 2016</li>
</ol>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="installation.html" class="btn btn-neutral float-right" title="Installation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="MABWiser Contextual Multi-Armed Bandits" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, FMR LLC

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>