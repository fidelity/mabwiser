{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "missing-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.5\n",
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import paramiko\n",
    "import sklearn\n",
    "import subprocess\n",
    "\n",
    "print(np.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-chest",
   "metadata": {},
   "source": [
    "## LinTS MovieLens Recommendations\n",
    "\n",
    "This notebook explores the differences in MovieLens recommendations across multiple NumPy environments. In particular, this notebook uses the preprocessed data generated in [LinTS MovieLens notebook](LinTS%20MovieLens.ipynb), with a bit of a twist: we add an `unknown` column, denoting whether we know the occupation of the user, by doing a logical or on the `other` and `none` columns. All scenarios use LinTS for generating recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile example_lints.py\n",
    "\n",
    "# Run this cell for every experiment\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import platform\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "\n",
    "from mabwiser.mab import MAB\n",
    "from mabwiser.linear import _RidgeRegression, _Linear\n",
    "\n",
    "from utils import contains_repeated_eigenvalues, all_positive_definite\n",
    "\n",
    "random_option = sys.argv[1]\n",
    "\n",
    "class LinTSExample(_RidgeRegression):\n",
    "    def predict(self, x):\n",
    "        if self.scaler is not None:\n",
    "            x = self._scale_predict_context(x) \n",
    "        if random_option == 'cholesky':\n",
    "            beta_sampled = rng2.multivariate_normal(self.beta, self.A_inv, method='cholesky')\n",
    "        else:\n",
    "            beta_sampled = rng2.multivariate_normal(self.beta, self.A_inv)\n",
    "        return np.dot(x, beta_sampled)\n",
    "    \n",
    "class LinearExample(_Linear):\n",
    "    factory = {\"ts\": LinTSExample}\n",
    "\n",
    "    def __init__(self, rng, arms, n_jobs=1, backend=None, l2_lambda=1, alpha=1, regression='ts', arm_to_scaler = None):\n",
    "        super().__init__(rng, arms, n_jobs, backend, l2_lambda, alpha, regression)\n",
    "       \n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.alpha = alpha\n",
    "        self.regression = regression\n",
    "\n",
    "        # Create ridge regression model for each arm\n",
    "        self.num_features = None\n",
    "\n",
    "        if arm_to_scaler is None:\n",
    "            arm_to_scaler = dict((arm, None) for arm in arms)\n",
    "\n",
    "        self.arm_to_model = dict((arm, LinearExample.factory.get(regression)(rng, l2_lambda,\n",
    "                                                                       alpha, arm_to_scaler[arm])) for arm in arms)\n",
    "\n",
    "\n",
    "base_path = os.path.dirname(__file__)\n",
    "\n",
    "# Dataset 1\n",
    "users = pd.read_csv(os.path.join(base_path, 'movielens_users.csv'))\n",
    "users['unknown'] = np.logical_or(users['other'], users['none'])\n",
    "responses = pd.read_csv(os.path.join(base_path, 'movielens_responses.csv'))\n",
    "train = users[users['set']=='train']\n",
    "test = users[users['set']=='test']\n",
    "\n",
    "train = train.merge(responses, how='left', on='user id')\n",
    "\n",
    "context_features = [c for c in users.columns if c not in ['user id', 'set']]\n",
    "none_ind = context_features.index('none')\n",
    "other_ind = context_features.index('other')\n",
    "\n",
    "decisions = MAB._convert_array(train['item id'])\n",
    "rewards = MAB._convert_array(train['rated'])\n",
    "contexts = MAB._convert_matrix(train[context_features]).astype('float')\n",
    "test_contexts = MAB._convert_matrix(test[context_features]).astype('float')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "contexts = scaler.fit_transform(contexts)\n",
    "test_contexts = scaler.transform(test_contexts)\n",
    "item_ids = list(responses['item id'].unique())\n",
    "\n",
    "if random_option == 'randomstate':\n",
    "    rng = np.random.RandomState(seed=11)\n",
    "    rng2 = rng\n",
    "elif random_option == 'svd':\n",
    "    rng = np.random.RandomState(seed=11)\n",
    "    rng2 = np.random.default_rng(11)\n",
    "elif random_option == 'cholesky':\n",
    "    rng = np.random.RandomState(seed=11)\n",
    "    rng2 = np.random.default_rng(11)\n",
    "\n",
    "mab = LinearExample(rng=rng, arms=item_ids, l2_lambda=1, alpha=1, regression='ts', n_jobs=1, backend=None)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "mab.fit(decisions, rewards, contexts)\n",
    "print(contains_repeated_eigenvalues(mab))\n",
    "print(all_positive_definite(mab))\n",
    "exps = mab.predict_expectations(test_contexts)\n",
    "\n",
    "recs = [max(user_exps, key=user_exps.get).item() for user_exps in exps]\n",
    "print(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-smell",
   "metadata": {},
   "source": [
    "We try training a MAB model and getting a recommendation from the model across 4 different environments:\n",
    "1. OpenBLAS-backed NumPy on MacOS Catalina\n",
    "2. MKL-backed NumPy on MacOS Catalina\n",
    "3. OpenBLAS-backed NumPy on Ubuntu 18.04\n",
    "4. MKL-backed NumPy on Ubuntu 18.04\n",
    "\n",
    "All environments contain NumPy version 1.18.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "revised-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ssh_config.json') as fp:\n",
    "    conf = json.load(fp)\n",
    "\n",
    "local_conf = {'host_name': 'localhost'}\n",
    "\n",
    "envs = [\n",
    "    ('mac_openblas', local_conf, os.path.expanduser('~/Tools/miniconda3/envs/reprod/bin/python')),\n",
    "    ('mac_mkl', local_conf, os.path.expanduser('~/Tools/miniconda3/envs/reprod2/bin/python')),\n",
    "    ('linux_openblas', conf, '$HOME/Tools/miniconda3/envs/reprod/bin/python'),\n",
    "    ('linux_mkl', conf, '$HOME/Tools/miniconda3/envs/reprod2/bin/python'),\n",
    "]\n",
    "\n",
    "def test_envs(env_lis, script, option):\n",
    "    all_vals = []\n",
    "    for env_name, conf, python_exec in env_lis:\n",
    "        print(f'Running {env_name}...')\n",
    "        if conf['host_name'] == 'localhost':\n",
    "            res = subprocess.run([python_exec, script, option], capture_output=True).stdout.decode('utf-8').strip()\n",
    "            contains_repeated_eigenvalues, all_positive_definite, res = res.split('\\n')\n",
    "            print(f\"Contains repeated eigenvalues: {contains_repeated_eigenvalues}\")\n",
    "            print(f\"All covariances positive definite: {all_positive_definite}\")\n",
    "            all_vals.append(eval(res))\n",
    "        else:\n",
    "            with paramiko.SSHClient() as ssh:\n",
    "                ssh.load_system_host_keys()\n",
    "                ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "                ssh.connect(hostname=conf['host_name'], username=conf['username'], key_filename=os.path.expanduser(conf['key_filename']))\n",
    "                with ssh.open_sftp() as ftp:\n",
    "                    ftp.put(script, f'/tmp/{script}')\n",
    "                    ftp.put('utils.py', '/tmp/utils.py')\n",
    "                    ftp.put('movielens_users.csv', '/tmp/movielens_users.csv')\n",
    "                    ftp.put('movielens_responses.csv', '/tmp/movielens_responses.csv')\n",
    "\n",
    "                _, stdout, stderr = ssh.exec_command(f'{python_exec} /tmp/{script} {option}', get_pty=True)\n",
    "\n",
    "                # Log the stdout as it comes\n",
    "                contains_repeated_eigenvalues, all_positive_definite, res = [line.strip() for line in stdout.readlines()]\n",
    "                print(f\"Contains repeated eigenvalues: {contains_repeated_eigenvalues}\")\n",
    "                print(f\"All covariances positive definite: {all_positive_definite}\")\n",
    "                all_vals.append(eval(res))\n",
    "\n",
    "    return np.unique(all_vals, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-stick",
   "metadata": {},
   "source": [
    "### Scenario 1\n",
    "\n",
    "We test MovieLens data with the legacy `RandomState` class across the 4 different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "removable-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mac_openblas...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running mac_mkl...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running linux_openblas...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running linux_mkl...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 504,  168,  227,  151,  213,  441,  105,  119, 1210, 1286,  394,\n",
       "         822, 1435, 1471, 1615,  288, 1077, 1008,  257,  552,  762,  317,\n",
       "         288,  918,  636,  136, 1156,  412, 1679,  160, 1478,  181,  275,\n",
       "        1548,  728,  285,  262,  748,   11, 1657,  449,  249,  543,  655,\n",
       "         337,  169, 1489,  655,  179,    8,    1,  158,  271,  321,  288,\n",
       "        1101,  359, 1503,   14,   53,  568,  702,  712, 1224,  344, 1216,\n",
       "         298, 1093,  825,  879,  449,  210,   31,  137,  288, 1095,   11,\n",
       "         478,  269,  459,  488,  239,   17,  218, 1227,   53,  879, 1673,\n",
       "         765, 1203, 1123,  525,  232,  884,  288,    7, 1276, 1012,  455,\n",
       "         655, 1372, 1562,  177,  872,  732, 1014,  422,  422,  345,  294,\n",
       "         619,  789,  978,  239,  403, 1490,  756,  823,  306,  992, 1473,\n",
       "         302,   33,  990,  418,  642, 1302,  388,  228, 1430,  204,  121,\n",
       "         975,  319, 1166,  325,  186,  624, 1563,  612,  100, 1063,  810,\n",
       "        1092, 1388, 1047,    1, 1468,    4, 1094,  162,    7, 1449,  183,\n",
       "         318,  391,  516,  167, 1503,  469,  269, 1228, 1478,   12,  393,\n",
       "        1421, 1037,  395,  121,  160,  940, 1011,  877,   91,  484,  694,\n",
       "         632, 1025,  435,  273,   94,  648,  609,  288, 1532,  919,  117,\n",
       "        1014,   35,  130,  583,  213,  953,  204,  452,  273,    7,  719,\n",
       "         742,  124,  172,  518,  420,  334,   43,   25, 1214,  742,  950,\n",
       "         118,  248, 1003,  581,  273,   97, 1554,  578,  421,  268,  625,\n",
       "         631, 1194,  250,  322,   89,  237, 1319, 1210,   13, 1009, 1160,\n",
       "        1143, 1086,  774,  864, 1022, 1121,  343,  835,  888,  493, 1604,\n",
       "        1537,  515, 1128, 1363,  983,  981,   76, 1045,  288,  475,  712,\n",
       "         657,  947, 1174,  288,  591,  846,  678,  448,  163, 1345, 1157,\n",
       "         240,   89,  146, 1673, 1239,  180,  650, 1137,  529, 1257,  309,\n",
       "         553,  920, 1002, 1388,  455,  547, 1147,  575],\n",
       "       [ 504, 1501,  227,  509, 1045,  441,  105,  119,    1, 1286,  394,\n",
       "         822, 1435, 1471, 1615,  288,  303,  251,  117,  204,  762,  317,\n",
       "         288,  801,  950,  136,  344,  412, 1679,  160, 1478,    7, 1492,\n",
       "         430,  939,  285,  262,  749,   11,  321,  732,  249, 1452,  655,\n",
       "         337,  169,  112, 1479,  179,  619,    1,  158,  271, 1092,  288,\n",
       "         951,  145,  945,  591,   53,  249,  702, 1185, 1224,  344,  786,\n",
       "          90,  406,  358,  805, 1367,  210,   31,   10,  288,  188,   11,\n",
       "         674,  269,  981,  488,  239,   17,  218,  612,  342,  879, 1673,\n",
       "         568, 1203, 1422,  525,  232,  884,  743,  342, 1359,  328,  595,\n",
       "         835,  516, 1562,  235,   13,  732, 1014,  806,  422,  345, 1412,\n",
       "         537,  288, 1645,  616,  403, 1594,  756, 1450, 1647,  992,  950,\n",
       "         858,   33, 1315,  418,  642, 1056, 1201,  228,  846,  204,  628,\n",
       "         111,  921,  507, 1346,  186,  624, 1563,  612,  100, 1063, 1307,\n",
       "        1092, 1388, 1047,    1, 1468,    4, 1094,  162,    1, 1449,  183,\n",
       "         515,  391,  516,  167,  155,  401,  269,   29, 1354, 1546,    1,\n",
       "          85, 1037,  395,  588,  217,  940,  382,  877,   91,  484,  969,\n",
       "         951, 1574,  510,  273,  926,  648,  315,  288,  183, 1611,  619,\n",
       "        1014,   35,  130,  583,  211,  953,  532, 1641,  273, 1284,  719,\n",
       "         742,  124,  517,  518,  420,  579,   43, 1241,  272,  742,  950,\n",
       "         845,  248,  455,  581, 1215,   97, 1554,  403,   49,  268,  410,\n",
       "        1656,  582,  235,  411,   89, 1324, 1319,  988,   13,  275,  285,\n",
       "        1143,   86,  157,  864, 1022, 1121,  343,  835,  888,  493, 1604,\n",
       "        1537,  515, 1128, 1597,  983,  596,  659,  837,  288,  121,  712,\n",
       "         657,  694, 1174,  288,  245,  846,  326,  448,  707,  485, 1137,\n",
       "         206,  760,  146,  240,  111,  180,  650,  615, 1608,  622,  907,\n",
       "        1246,  920,   53, 1572,  780,  926,  684,  575],\n",
       "       [ 585,   80,  582,  275,  611, 1060,  468,   55,  823,  751, 1475,\n",
       "        1398,  957,  953,   56, 1044, 1103,  866,    4,  258,  390,  196,\n",
       "         111,   68,  914,  521, 1377,  756,  226,  741, 1280,  273,  221,\n",
       "         425,  796,  398,   17,  500,  240, 1571, 1505,  475,  836,  338,\n",
       "          49,  100,  595,  631,  215,  508,  248, 1471,  117,  846,  231,\n",
       "         141,  288,  759, 1682,  147,  288,  565,  799, 1135,  686,  756,\n",
       "         186,  664, 1103,  498,  403,   53, 1640,  867, 1036, 1325, 1616,\n",
       "         285, 1329,  545, 1241,  845,  411, 1041, 1089,  986,  373,  628,\n",
       "         288, 1345,  574,  487,  502,  873,  117,  636,  892,  322,  298,\n",
       "         475,  690,  258,  682,   87,  154,  748, 1635,  673,  808,  383,\n",
       "         233,    1, 1587, 1540, 1499,  322,  934,  168,  302,  951,  623,\n",
       "         231,    1,  373, 1280,    1,  990,   72,  530,  371,  234,  411,\n",
       "        1549,  980,  377,  521,  492, 1019,  943, 1401,  403, 1408,   89,\n",
       "         942, 1449,  300,   40,  829,  238,  113,  467,  288,  192,  202,\n",
       "         436,  514,   80, 1162,  449,  660, 1199,  128, 1449,  894,   84,\n",
       "         780,  350,  327,   24,  927,  288,  381,  391,  233,  174, 1506,\n",
       "         473,  191,  190,  266,  420, 1367,  546,  763,  823, 1593,  477,\n",
       "         288,  796,  138, 1203,  515,  109,  183, 1544,  682,   17,  705,\n",
       "         400, 1206, 1041,  456, 1086,  286,   71,  225,  137,  304,  311,\n",
       "         528,  440, 1365,  330,  763,  188, 1522,  431, 1177,  288,   98,\n",
       "         215,  322,  288, 1328,    7, 1563, 1347,  471, 1582,  216,  176,\n",
       "         183,   25,  318,  851,   82,  459,  672,  285,  934,  903, 1530,\n",
       "          55, 1537,  762,  328,  405,  324,  320, 1538,  237,  111,   96,\n",
       "        1161,  344,  807,  273,  428,  288,  805, 1104, 1365,  619,  168,\n",
       "        1324, 1274, 1508,  260,  724,  286,  317,  268,  141,  883,  451,\n",
       "         455,  208,  976,  486,   65,   24,  246,  444]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_envs(envs, 'example_lints.py', 'randomstate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-english",
   "metadata": {},
   "source": [
    "As we can see, the top 1 recommendations generated for each user can be quite different across multiple runs. In fact, these 4 different environments lead to 3 different sets of recommendations, showing clearly that setting the seed isn't enough for reproducibility here.\n",
    "\n",
    "### Scenario 2\n",
    "We test MovieLens data using the new `Generator` class with default arguments across 4 different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "handled-blank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mac_openblas...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running mac_mkl...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running linux_openblas...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running linux_mkl...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  31,  399,  483, 1166,  517,  590,   32, 1272,  196,  537,  658,\n",
       "        1262,  475, 1676,  987,  332,   71, 1659,  550,   27,  700,  126,\n",
       "         288, 1123,  199,  434, 1181,  593, 1346,  993, 1209,  693,  604,\n",
       "         126, 1033,  486,   62,  952,  759,  857,  315, 1400,  206,  391,\n",
       "         332, 1402,  214,  536,  204,  917, 1053, 1117,    7, 1561,  288,\n",
       "         221,  873,  937, 1250,   11, 1052,  615,  956,  155, 1429, 1473,\n",
       "         222,  405,  469,    7,  183,  597,  511, 1675,   55,  582,  597,\n",
       "         103,  540, 1270,  286,  547,  775, 1344,  256, 1596,  336,  402,\n",
       "         846,  576,  335,  994,  272, 1225,  222,  226,  668,  893,  121,\n",
       "        1158,  402,  258,  586, 1009,  435,  748,  879, 1652, 1148,  866,\n",
       "         909,  172, 1137,  482,  186, 1640, 1674,  581,  353,   89,  162,\n",
       "         218,  196,  690,  949,  174,  245,  127,   65,  816,  227,    7,\n",
       "         547,  187, 1480,  549,  946,  764,  183, 1010,  562,  671,  211,\n",
       "         839,   87,  285,   15,  968,   69,  332, 1212,   24, 1560, 1484,\n",
       "          60,  977, 1557, 1205,  792,  655,   52, 1052,  921, 1361,    4,\n",
       "         337,   76,  601,   24,  275, 1054,  644,  563,  759,  579,  551,\n",
       "         307,  135,  665,  288, 1014,  913, 1056,  928,  470,  959,  800,\n",
       "         815, 1137,  635,  391,  429,  947,   50,  960,  651,  619,  993,\n",
       "        1534,  357,  714,  695, 1128,  912,  227,  288,  184, 1106,  462,\n",
       "         255,  763,  164, 1189, 1220,  100,  972,  423,  288,  628,  373,\n",
       "         603,  321, 1062,  257,  732,  368,  201, 1585, 1070,  873,   44,\n",
       "        1203,  255,    7,  480,  550, 1406,   13, 1456, 1086,  588,  762,\n",
       "        1635, 1580,  183, 1083,  650,  714,  573,  448, 1016,    7,  174,\n",
       "          97,  173,  472,  586,  879,  866,  292,  164,  483, 1027,  229,\n",
       "         148,  205, 1336, 1373,  220,  170,  609, 1194, 1679, 1057,  122,\n",
       "          93,  828,  765,  504,  435,  258,  279, 1567],\n",
       "       [1369,  122,  599, 1229, 1681,  269,  109,  377,  156, 1045,  167,\n",
       "        1381, 1259,  190,  444, 1426,  218, 1048,  558,  686,  243,   82,\n",
       "         318,   24,  751, 1110, 1667,  278,   96,  258, 1370,   11,  126,\n",
       "         659, 1352, 1593, 1088, 1157,   53,   13,  403,  288,  369,  656,\n",
       "        1010,  989,  544,   28,   89,   23,  117,  780,  288, 1050,  763,\n",
       "         687, 1154,  283,  283,  288,  826,  623,  444, 1185, 1054, 1396,\n",
       "          41,  984,  682,  186,  724,  288,  203, 1038,  783,  171,  783,\n",
       "         519, 1415,  386, 1539, 1305,  117,  475, 1198,  608,  332,  682,\n",
       "         288,  352,  351, 1375,  997,  340,    1,  695,  139, 1499,   79,\n",
       "         154, 1239,  770, 1191,  162,  530,  111, 1051,  319, 1125,  627,\n",
       "         879,    7,  512, 1111,  177,  252,  616,  176,  530, 1623,  898,\n",
       "        1669,  943, 1645, 1613, 1128,  682,  137, 1618, 1123,  423,  581,\n",
       "        1391,  408,  307,  368,  121, 1318,  188, 1491,  176,  258, 1109,\n",
       "         369, 1371,  844,  233,  934,   91, 1412, 1200,  742, 1561,  482,\n",
       "         205, 1262,  301, 1679,   79,   73, 1401,  682,  958, 1016,  121,\n",
       "         259,  980,  566,  238,  272,  406,  809,  639,  169,  311,  335,\n",
       "        1318,  953, 1224, 1096, 1254,  231, 1553,  320,    1,  405,  657,\n",
       "         902,  151,  213,   89,  481, 1059,   24,  366,   11,  475, 1083,\n",
       "         877, 1106, 1250, 1174,  711,  482,  100, 1599,  497,  262, 1630,\n",
       "         471,  294,  299,  655,  455,  655,  925,    1,  411, 1110, 1008,\n",
       "         230,  338,  288, 1059,  159,  247,  506, 1091, 1321,    3,  487,\n",
       "         665,  237,  490,  879,  217,  303,  438,  519,  912,  327,  230,\n",
       "         540,  529, 1168, 1288,  448,  748, 1461,  356,  908,  852,  568,\n",
       "        1662,   71, 1225,  121, 1586,  313, 1435,  448,  198,  888,  175,\n",
       "         515,  101,  618,   81, 1513,  813,  277,  555, 1002,  177,  216,\n",
       "         928,  264, 1146,  520,  684,  694,  761,   39],\n",
       "       [1369,  597,  599, 1014, 1681,  269,  109, 1335,  156, 1045,  167,\n",
       "        1233, 1259,  190,  444,  403,  403,  433, 1119,  250,  243,   82,\n",
       "         318,  546,  751, 1110,  600,  278,   96,  258, 1494,   11,  126,\n",
       "         322,  887, 1593, 1088, 1157,   53,   13,   69,  288,  762,  656,\n",
       "         321,  989,  544,  759,   89,  258,   63,  780,  295, 1316,  763,\n",
       "         841,  121,  283,  233,  288,  886,  623, 1417,  278, 1054,  860,\n",
       "          23,  984,  249,  783,  724,  288,  203, 1038,  783,  601,   79,\n",
       "         640,  601,  456, 1539, 1305,  117,  475,  760,  774,  748,  682,\n",
       "         288,  352,  639, 1375,  997,  340,    1,  250,   46,  756,   79,\n",
       "          68,  754,  770, 1211,  508,  684,  111, 1051,  319,  162, 1002,\n",
       "         879,    7,  512, 1111,  177, 1229,  616,  176,  530, 1623,  969,\n",
       "        1062,  943, 1645,  988, 1128,  760,  137, 1618, 1123,  423,  161,\n",
       "        1072, 1070,  307,   76,  121, 1318,  188, 1491,  176,  928,  761,\n",
       "         369, 1371, 1308,  928,  509, 1669, 1412, 1200,  587, 1561,  482,\n",
       "         527, 1262,  301, 1679,   79,  370,  618, 1280,  270, 1234,  229,\n",
       "         879,  980,  566,  455,  272, 1651,  854,  639,  169,  311,  597,\n",
       "        1318,  953,   45,  461, 1254, 1090,  326,  320,    1,   24,  926,\n",
       "         288,  151,  213,   89,  526, 1059,   24,  480,   11,  475, 1606,\n",
       "         313, 1106,  499, 1174, 1178,  482,  100,   11,   70, 1398,   45,\n",
       "        1023, 1675, 1131,   65,  455,  655,  925,   97,  123,  567,  279,\n",
       "         319,  338,  288, 1059,  159,  247,  689, 1098, 1321,  672,  487,\n",
       "         665,  933,   48,  129,  217, 1108,  218,  130,  912,  327,  230,\n",
       "         540,  624, 1168,  609, 1523,  276,  713,  356,  908, 1342,  568,\n",
       "        1662, 1491, 1225,  121, 1586,  313,  495,  448,  177,  371,  176,\n",
       "        1337,  818,  618,   15,  371,  813,  277,  555, 1002,  177, 1349,\n",
       "         386,  264, 1146,  177,  684,  694,  254,   39]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_envs(envs, 'example_lints.py', 'svd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-merchant",
   "metadata": {},
   "source": [
    "We can see that even with the new `Generator` class, which uses SVD decomposition by default, we still have a problem, with 4 different environments giving 3 different set of recommendations.\n",
    "\n",
    "### Scenario 3\n",
    "We test MovieLens data using the new `Generator` class with Cholesky decomposition method, across 4 different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cutting-burton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mac_openblas...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running mac_mkl...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running linux_openblas...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n",
      "Running linux_mkl...\n",
      "Contains repeated eigenvalues: True\n",
      "All covariances positive definite: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 655,  235,  137,  444,  134,  150,  121, 1541,  259, 1588, 1246,\n",
       "         414, 1354,  302, 1330,  288, 1289,  577,  318,  554,  751,  298,\n",
       "         249, 1019,  539,  510,   79,  996,   17,  311,  321,  288,  416,\n",
       "         870, 1106, 1482,  929,  172,  808,  475,  196, 1384,   65, 1320,\n",
       "         158,  396, 1114,  355, 1458,  271,  682,    4,  288, 1117,  288,\n",
       "         519,  278,  981, 1515, 1077,  455,  595,   73,   66, 1629,  269,\n",
       "         559,  410,  520, 1408,    1,  117,  879, 1619,  273,  627,  679,\n",
       "         286,  149,  456, 1222, 1081,  742,  343,  341,  987,  817,  939,\n",
       "         545,  435, 1618, 1412,  828,  150,  121,  150,   32, 1254,  567,\n",
       "         856, 1629,  255,  651,   30,  791,  111, 1051, 1570,  225,  845,\n",
       "         342,  268, 1131, 1349,  518,  257,  295,  839,  304,   35,   99,\n",
       "         270,  147, 1544,  819,  423, 1532, 1085,   92,  692,  180,  411,\n",
       "        1434,  201, 1057,  498,  231,    1,  708,  603,  357, 1664,  177,\n",
       "          86,  631,   97,  118,  478,  196,  383,  277,  628,  259,  673,\n",
       "         218,  736,  498,  526, 1211,  769,   52,  754,   42,  288,  195,\n",
       "        1248,   76, 1426,  763,  283, 1271, 1051,  427,  363,  213, 1281,\n",
       "         469, 1115,  855,  403, 1254, 1008, 1304,  700,    4,   33,  117,\n",
       "         951,  605, 1289,   89,  101,  475, 1161, 1225,   24,  121,  313,\n",
       "         403, 1258,  891,  547,  964,  692,  405, 1206,  480, 1326, 1211,\n",
       "         660,  619,  780,  746,  288,  902,  979,    1,  758,  288,   40,\n",
       "         194,  187,  288,  355,  746,  346, 1101, 1550,  201,  237,   73,\n",
       "         321,  557,  125,  172,  288,  971,  288,  671, 1008,  520,  385,\n",
       "         133, 1215,  719, 1288,  532,  748, 1186,  370,  122,  756,  132,\n",
       "         601, 1144, 1246,  546, 1132, 1016,  523,  991,  883,  983,  640,\n",
       "         944,  188,  805,   85,   73,   20,  825, 1412,  752, 1466,   66,\n",
       "         122,  771,  273, 1595,  642,   72,  358, 1040]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_envs(envs, 'example_lints.py', 'cholesky')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-postcard",
   "metadata": {},
   "source": [
    "We can see that using Cholesky decomposition, there is only one single set of recommendations the users receive, further showing that Cholesky decomposition is important for reproducibility purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:reprod]",
   "language": "python",
   "name": "conda-env-reprod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
