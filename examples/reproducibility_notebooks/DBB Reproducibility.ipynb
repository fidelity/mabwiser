{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fitted-passage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.10 (default, Feb 26 2021, 10:16:00) \n",
      "[Clang 10.0.0 ]\n",
      "1.18.5\n",
      "0.24.1\n",
      "1.15.5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import paramiko\n",
    "import sklearn\n",
    "import sys\n",
    "import subprocess\n",
    "import tensorflow as tf\n",
    "\n",
    "print(sys.version)\n",
    "print(np.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-thousand",
   "metadata": {},
   "source": [
    "## Deep Bayesian Bandits Reproducibility\n",
    "\n",
    "This notebook explores the reproducibility around the [Deep Bayesian Bandits](https://github.com/tensorflow/models/tree/archive/research/deep_contextual_bandits) work by Google. We look at the LinTS implementation, which forms the baseline of their experiments.\n",
    "\n",
    "In order to run these experiments, please perform the steps below:\n",
    "- Create two environments using the versions above, one using `conda install`, and one using `pip install`. This ensures that one of the environments uses MKL and the other uses OpenBLAS.\n",
    "- Download mushroom data from [readme](https://github.com/tensorflow/models/tree/archive/research/deep_contextual_bandits#real-world-datasets) and place in this directory.\n",
    "- Clone the [tensorflow models repo](https://github.com/tensorflow/models), switch to the `archive` branch, and copy `models/research/deep_contextual_bandits/bandits` folder to this directory.\n",
    "- Run the cell below to overwrite the LinTS implementation file. This updates the multivariate sampling such that we can select the method to use while sampling, between SVD and Cholesky. Note that the SVD method was used in the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hungry-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bandits/algorithms/linear_full_posterior_sampling.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bandits/algorithms/linear_full_posterior_sampling.py\n",
    "# Copyright 2018 The TensorFlow Authors All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Contextual algorithm that keeps a full linear posterior for each arm.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import invgamma\n",
    "\n",
    "from bandits.core.bandit_algorithm import BanditAlgorithm\n",
    "from bandits.core.contextual_dataset import ContextualDataset\n",
    "\n",
    "\n",
    "class LinearFullPosteriorSampling(BanditAlgorithm):\n",
    "  \"\"\"Thompson Sampling with independent linear models and unknown noise var.\"\"\"\n",
    "\n",
    "  def __init__(self, name, hparams):\n",
    "    \"\"\"Initialize posterior distributions and hyperparameters.\n",
    "\n",
    "    Assume a linear model for each action i: reward = context^T beta_i + noise\n",
    "    Each beta_i has a Gaussian prior (lambda parameter), each sigma2_i (noise\n",
    "    level) has an inverse Gamma prior (a0, b0 parameters). Mean, covariance,\n",
    "    and precision matrices are initialized, and the ContextualDataset created.\n",
    "\n",
    "    Args:\n",
    "      name: Name of the algorithm.\n",
    "      hparams: Hyper-parameters of the algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    self.name = name\n",
    "    self.hparams = hparams\n",
    "    self.rng = np.random.default_rng(self.hparams.seed)\n",
    "\n",
    "    # Gaussian prior for each beta_i\n",
    "    self._lambda_prior = self.hparams.lambda_prior\n",
    "\n",
    "    self.mu = [\n",
    "        np.zeros(self.hparams.context_dim + 1)\n",
    "        for _ in range(self.hparams.num_actions)\n",
    "    ]\n",
    "\n",
    "    self.cov = [(1.0 / self.lambda_prior) * np.eye(self.hparams.context_dim + 1)\n",
    "                for _ in range(self.hparams.num_actions)]\n",
    "\n",
    "    self.precision = [\n",
    "        self.lambda_prior * np.eye(self.hparams.context_dim + 1)\n",
    "        for _ in range(self.hparams.num_actions)\n",
    "    ]\n",
    "\n",
    "    # Inverse Gamma prior for each sigma2_i\n",
    "    self._a0 = self.hparams.a0\n",
    "    self._b0 = self.hparams.b0\n",
    "\n",
    "    self.a = [self._a0 for _ in range(self.hparams.num_actions)]\n",
    "    self.b = [self._b0 for _ in range(self.hparams.num_actions)]\n",
    "\n",
    "    self.t = 0\n",
    "    self.data_h = ContextualDataset(hparams.context_dim,\n",
    "                                    hparams.num_actions,\n",
    "                                    intercept=True)\n",
    "\n",
    "  def action(self, context):\n",
    "    \"\"\"Samples beta's from posterior, and chooses best action accordingly.\n",
    "\n",
    "    Args:\n",
    "      context: Context for which the action need to be chosen.\n",
    "\n",
    "    Returns:\n",
    "      action: Selected action for the context.\n",
    "    \"\"\"\n",
    "\n",
    "    # Round robin until each action has been selected \"initial_pulls\" times\n",
    "    if self.t < self.hparams.num_actions * self.hparams.initial_pulls:\n",
    "      return self.t % self.hparams.num_actions\n",
    "\n",
    "    # Sample sigma2, and beta conditional on sigma2\n",
    "    sigma2_s = [\n",
    "        self.b[i] * invgamma.rvs(self.a[i])\n",
    "        for i in range(self.hparams.num_actions)\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        if self.hparams.method == 'default':\n",
    "            beta_s = [\n",
    "              np.random.multivariate_normal(self.mu[i], sigma2_s[i] * self.cov[i])\n",
    "              for i in range(self.hparams.num_actions)\n",
    "            ]\n",
    "        else:\n",
    "            beta_s = [\n",
    "                self.rng.multivariate_normal(self.mu[i], sigma2_s[i] * self.cov[i], method=self.hparams.method)\n",
    "                for i in range(self.hparams.num_actions)\n",
    "            ]\n",
    "    except np.linalg.LinAlgError as e:\n",
    "      # Sampling could fail if covariance is not positive definite\n",
    "      print('Exception when sampling from {}.'.format(self.name))\n",
    "      print('Details: {} | {}.'.format(e.message, e.args))\n",
    "      d = self.hparams.context_dim + 1\n",
    "      beta_s = [\n",
    "          np.random.multivariate_normal(np.zeros((d)), np.eye(d))\n",
    "          for i in range(self.hparams.num_actions)\n",
    "      ]\n",
    "\n",
    "    # Compute sampled expected values, intercept is last component of beta\n",
    "    vals = [\n",
    "        np.dot(beta_s[i][:-1], context.T) + beta_s[i][-1]\n",
    "        for i in range(self.hparams.num_actions)\n",
    "    ]\n",
    "\n",
    "    return np.argmax(vals)\n",
    "\n",
    "  def update(self, context, action, reward):\n",
    "    \"\"\"Updates action posterior using the linear Bayesian regression formula.\n",
    "\n",
    "    Args:\n",
    "      context: Last observed context.\n",
    "      action: Last observed action.\n",
    "      reward: Last observed reward.\n",
    "    \"\"\"\n",
    "\n",
    "    self.t += 1\n",
    "    self.data_h.add(context, action, reward)\n",
    "\n",
    "    # Update posterior of action with formulas: \\beta | x,y ~ N(mu_q, cov_q)\n",
    "    x, y = self.data_h.get_data(action)\n",
    "\n",
    "    # The algorithm could be improved with sequential update formulas (cheaper)\n",
    "    s = np.dot(x.T, x)\n",
    "\n",
    "    # Some terms are removed as we assume prior mu_0 = 0.\n",
    "    precision_a = s + self.lambda_prior * np.eye(self.hparams.context_dim + 1)\n",
    "    cov_a = np.linalg.inv(precision_a)\n",
    "    mu_a = np.dot(cov_a, np.dot(x.T, y))\n",
    "\n",
    "    # Inverse Gamma posterior update\n",
    "    a_post = self.a0 + x.shape[0] / 2.0\n",
    "    b_upd = 0.5 * (np.dot(y.T, y) - np.dot(mu_a.T, np.dot(precision_a, mu_a)))\n",
    "    b_post = self.b0 + b_upd\n",
    "\n",
    "    # Store new posterior distributions\n",
    "    self.mu[action] = mu_a\n",
    "    self.cov[action] = cov_a\n",
    "    self.precision[action] = precision_a\n",
    "    self.a[action] = a_post\n",
    "    self.b[action] = b_post\n",
    "\n",
    "  @property\n",
    "  def a0(self):\n",
    "    return self._a0\n",
    "\n",
    "  @property\n",
    "  def b0(self):\n",
    "    return self._b0\n",
    "\n",
    "  @property\n",
    "  def lambda_prior(self):\n",
    "    return self._lambda_prior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-advocate",
   "metadata": {},
   "source": [
    "We replicate the [quick start example](https://github.com/tensorflow/models/blob/archive/research/deep_contextual_bandits/example_main.py) from the Deep Contextual Bandits research repo below, focusing on just LinTS, and evaluating the cumulative reward at the end. Note that all the seeds are set, such that the cumulative reward should be the same when the code is run in the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fewer-lemon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example_dcb.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example_dcb.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "\n",
    "from bandits.data.data_sampler import sample_mushroom_data\n",
    "from bandits.core.contextual_bandit import run_contextual_bandit\n",
    "from bandits.algorithms.linear_full_posterior_sampling import LinearFullPosteriorSampling\n",
    "\n",
    "if type(tf.contrib) != type(tf):\n",
    "    tf.contrib._warning = None\n",
    "\n",
    "random_option = sys.argv[1]\n",
    "np.random.seed(42)\n",
    "\n",
    "def sample_data(num_contexts):\n",
    "    num_actions = 2\n",
    "    context_dim = 117\n",
    "    file_name = os.path.join(os.path.dirname(__file__), 'mushroom.data')\n",
    "    dataset, opt_mushroom = sample_mushroom_data(file_name, num_contexts)\n",
    "    opt_rewards, opt_actions = opt_mushroom\n",
    "    return dataset, opt_rewards, opt_actions, num_actions, context_dim\n",
    "\n",
    "# Problem parameters\n",
    "num_contexts = 2000\n",
    "\n",
    "# Create dataset\n",
    "sampled_vals = sample_data(num_contexts)\n",
    "dataset, opt_rewards, opt_actions, num_actions, context_dim = sampled_vals\n",
    "\n",
    "hparams_linear = tf.contrib.training.HParams(num_actions=num_actions,\n",
    "                                             context_dim=context_dim,\n",
    "                                             a0=6,\n",
    "                                             b0=6,\n",
    "                                             lambda_prior=0.25,\n",
    "                                             initial_pulls=2,\n",
    "                                             seed=42,\n",
    "                                             method=random_option)\n",
    "\n",
    "algos = [\n",
    "      LinearFullPosteriorSampling('LinFullPost', hparams_linear),\n",
    "]\n",
    "t_init = time.time()\n",
    "results = run_contextual_bandit(context_dim, num_actions, dataset, algos)\n",
    "_, h_rewards = results\n",
    "\n",
    "\n",
    "reward = np.sum(h_rewards[:, 0])\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "announced-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ssh_config.json') as fp:\n",
    "    conf = json.load(fp)\n",
    "\n",
    "local_conf = {'host_name': 'localhost'}\n",
    "\n",
    "envs = [\n",
    "    ('mac_openblas', local_conf, os.path.expanduser('~/Tools/miniconda3/envs/dcb/bin/python')),\n",
    "    ('mac_mkl', local_conf, os.path.expanduser('~/Tools/miniconda3/envs/dcb2/bin/python')),\n",
    "    ('linux_openblas', conf, '$HOME/Tools/miniconda3/envs/dcb/bin/python'),\n",
    "    ('linux_mkl', conf, '$HOME/Tools/miniconda3/envs/dcb2/bin/python'),\n",
    "]\n",
    "\n",
    "def test_envs(env_lis, script, option):\n",
    "    all_vals = []\n",
    "    for env_name, conf, python_exec in env_lis:\n",
    "        print(f'Running {env_name}...')\n",
    "        if conf['host_name'] == 'localhost':\n",
    "            res = subprocess.run([python_exec, script, option], capture_output=True).stdout.decode('utf-8').strip()\n",
    "            all_vals.append(eval(res))\n",
    "        else:\n",
    "            with paramiko.SSHClient() as ssh:\n",
    "                ssh.load_system_host_keys()\n",
    "                ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "                ssh.connect(hostname=conf['host_name'], username=conf['username'], key_filename=os.path.expanduser(conf['key_filename']))\n",
    "                with ssh.open_sftp() as ftp:\n",
    "                    ftp.put(script, f'/tmp/{script}')\n",
    "                    ftp.put('mushroom.data', '/tmp/mushroom.data')\n",
    "                    for root, _, files in os.walk('bandits'):\n",
    "                        if not root.endswith('__pycache__'):\n",
    "                            try:\n",
    "                                ftp.mkdir(f'/tmp/{root}')\n",
    "                            except OSError:\n",
    "                                pass\n",
    "                            for file in files:\n",
    "                                local_file = os.path.join(root, file)\n",
    "                                ftp.put(local_file, f'/tmp/{local_file}')\n",
    "\n",
    "                _, stdout, stderr = ssh.exec_command(f'{python_exec} /tmp/{script} {option}', get_pty=True)\n",
    "\n",
    "                # Log the stdout as it comes\n",
    "                res = ''.join([line.strip() for line in stdout.readlines()])\n",
    "                all_vals.append(eval(res))\n",
    "\n",
    "    return all_vals, np.unique(all_vals, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-leader",
   "metadata": {},
   "source": [
    "### Option 1\n",
    "We use the default implementation, which uses `np.random.multivariate_random`, and set the global seed to ensure reproducibility in a single environment. Note that this is the same as using `np.random.RandomState`, as the global seed sets the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strategic-klein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mac_openblas...\n",
      "Running mac_mkl...\n",
      "Running linux_openblas...\n",
      "Running linux_mkl...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3830.0, 3925.0, 3590.0, 3360.0], array([3360., 3590., 3830., 3925.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_envs(envs, 'example_dcb.py', 'default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-graphic",
   "metadata": {},
   "source": [
    "The default implementation shows the problem: when running this code on different environments, even with different seeds, the cumulative regret is not deterministic.\n",
    "\n",
    "### Option 2\n",
    "We use the new `Generator` class with default parameters, which internally uses SVD for decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "million-taste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mac_openblas...\n",
      "Running mac_mkl...\n",
      "Running linux_openblas...\n",
      "Running linux_mkl...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3830.0, 3865.0, 3730.0, 3605.0], array([3605., 3730., 3830., 3865.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_envs(envs, 'example_dcb.py', 'svd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-savings",
   "metadata": {},
   "source": [
    "Again, running this code on different environments produces different results.\n",
    "\n",
    "### Option 3\n",
    "We use Cholesky decomposition with the new `Generator` class. Our hypothesis is that this will produce reproducible results across different environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "institutional-rochester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running mac_openblas...\n",
      "Running mac_mkl...\n",
      "Running linux_openblas...\n",
      "Running linux_mkl...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([4025.0, 4025.0, 4025.0, 4025.0], array([4025.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_envs(envs, 'example_dcb.py', 'cholesky')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-producer",
   "metadata": {},
   "source": [
    "As expected, using Cholesky decomposition leads to the same cumulative regret across all environments, alleviating the problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dcb]",
   "language": "python",
   "name": "conda-env-dcb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
